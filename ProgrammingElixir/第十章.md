

Chapter 10





Processing Collections—Enum and Stream




* * *



In this chapter, we’ll see

The Enum module

The Stream module

The Collectable protocol

Comprehensions



Elixir comes with a number of types that act as collections. We’ve already seen lists and dictionaries. There are also things such as ranges, files, dictionaries, and even functions. And as we’ll discuss when we look at protocols, you can also define your own.

Collections differ in their implementation. But they all share something: you can iterate through them. Some of them share an additional trait: you can add things to them.

Technically, things that can be iterated are said to implement the Enumerable protocol.

Elixir provides two modules that have a bunch of iteration functions. The Enum module is the workhorse for collections. You’ll use it all the time. I strongly recommend getting to know it.

The Stream module lets you enumerate a collection lazily. This means that the next value is calculated only when it is needed. You’ll use this less often, but when you do it’s a lifesaver.

I don’t want to fill this book with a list of all the APIs. You’ll find the definitive (and up-to-date) list online.[16] Instead, I’ll illustrate some common uses and let you browse the documentation for yourself. (But please do remember to do so. Much of Elixir’s power comes from these libraries.)





Enum—Processing Collections


The Enum module is probably the most used of all the Elixir libraries. Employ it to iterate, filter, combine, split, and otherwise manipulate collections. Here are some common tasks:

Convert any collection into a list: iex> list = Enum.to_list 1..5



[1, 2, 3, 4, 5]





Concatenate collections: iex> Enum.concat([1,2,3], [4,5,6])



[1, 2, 3, 4, 5, 6]



iex> Enum.concat [1,2,3], 'abc'



[1, 2, 3, 97, 98, 99]





Create collections whose elements are some function of the original: iex> Enum.map(list, &(&1 * 10))



[10, 20, 30, 40, 50]



iex> Enum.map(list, &String.duplicate("*", &1))



["*", "**", "***", "****", "*****"]





Select elements by position or criteria: iex> Enum.at(10..20, 3)



13



iex> Enum.at(10..20, 20)



nil



iex> Enum.at(10..20, 20, :no_one_here)



:no_one_here



iex> Enum.filter(list, &(&1 > 2))



[3, 4, 5]



iex> Enum.filter(list, &Integer.is_even/1)



[2, 4]



iex> Enum.reject(list, &Integer.is_even/1)



[1, 3, 5]





Sort and compare elements: iex> Enum.sort ["there", "was", "a", "crooked", "man"]



["a", "crooked", "man", "there", "was"]



iex> Enum.sort ["there", "was", "a", "crooked", "man"],



... &(String.length(&1) <= String.length(&2))



["a", "man", "was", "there", "crooked"]



iex(4)> Enum.max ["there", "was", "a", "crooked", "man"]



"was"



iex(5)> Enum.max_by ["there", "was", "a", "crooked", "man"], &String.length/1



"crooked"





Split a collection: iex> Enum.take(list, 3)



[1, 2, 3]



iex> Enum.take_every list, 2



[1, 3, 5]



iex> Enum.take_while(list, &(&1 < 4))



[1, 2, 3]



iex> Enum.split(list, 3)



{[1, 2, 3], [4, 5]}



iex> Enum.split_while(list, &(&1 < 4))



{[1, 2, 3], [4, 5]}





Join a collection: iex> Enum.join(list)



"12345"



iex> Enum.join(list, ", ")



"1, 2, 3, 4, 5"





Predicate operations: iex> Enum.all?(list, &(&1 < 4))



false



iex> Enum.any?(list, &(&1 < 4))



true



iex> Enum.member?(list, 4)



true



iex> Enum.empty?(list)



false





Merge collections: iex> Enum.zip(list, [:a, :b, :c])



[{1, :a}, {2, :b}, {3, :c}]



iex> Enum.with_index(["once", "upon", "a", "time"])



[{"once", 0}, {"upon", 1}, {"a", 2}, {"time", 3}]





Fold elements into a single value: iex> Enum.reduce(1..100, &(&1+&2))



5050



iex> Enum.reduce(["now", "is", "the", "time"],fn word, longest ->



...> if String.length(word) > String.length(longest) do



...> word



...> else



...> longest



...> end



...> end)



"time"



iex> Enum.reduce(["now", "is", "the", "time"], 0, fn word, longest ->



...> if String.length(word) > longest do



...> String.length(word)



...> else



...> longest



...> end



...> end)



4





Deal a hand of cards: iex> import Enum



iex> deck = for rank <- '23456789TJQKA', suit <- 'CDHS', do: [suit,rank]



['C2', 'D2', 'H2', 'S2', 'C3', 'D3', ... ]



iex> deck |> shuffle |> take(13)



['DQ', 'S6', 'HJ', 'H4', 'C7', 'D6', 'SJ', 'S9', 'D7', 'HA', 'S4', 'C2', 'CT']



iex> hands = deck |> shuffle |> chunk(13)



[['D8', 'CQ', 'H2', 'H3', 'HK', 'H9', 'DK', 'S9', 'CT', 'ST', 'SK', 'D2', 'HA'],



['C5', 'S3', 'CK', 'HQ', 'D3', 'D4', 'CA', 'C8', 'S6', 'DQ', 'H5', 'S2', 'C4'],



['C7', 'C6', 'C2', 'D6', 'D7', 'SA', 'SQ', 'H8', 'DT', 'C3', 'H7', 'DA', 'HT'],



['S5', 'S4', 'C9', 'S8', 'D5', 'H4', 'S7', 'SJ', 'HJ', 'D9', 'DJ', 'CJ', 'H6']]





A Note on Sorting


In our example of sort, we used

Enum.sort(["once", "upon", "a", "time"],



&(String.length(&1) <= String.length(&2))





It’s important to use <= and not just < if you want the sort to be stable.





Your Turn


Exercise: ListsAndRecursion-5

Implement the following Enum functions using no library functions or list comprehensions: all?, each, filter, split, and take. You may need to use an if statement to implement filter. The syntax for this is if condition do



expression(s)



else



expression(s)



end





Exercise: ListsAndRecursion-6

(Hard) Write a flatten(list) function that takes a list that may contain any number of sublists, which themselves may contain sublists, to any depth. It returns the elements of these lists as a flat list. iex> MyList.flatten([ 1, [ 2, 3, [4] ], 5, [[[6]]]])



[1,2,3,4,5,6]





Hint: You may have to use Enum.reverse to get your result in the correct order.





Streams—Lazy Enumerables




In Elixir, the Enum module is greedy. This means that when you pass it a collection, it potentially consumes all the contents of that collection. It also means the result will typically be another collection. Look at the following pipeline:

enum/pipeline.exs

[ 1, 2, 3, 4, 5 ]



|> Enum.map(&(&1*&1))



|> Enum.with_index



|> Enum.map(fn {value, index} -> value - index end)



|> IO.inspect #=> [1,3,7,13,21]





The first map function takes the original list and creates a new list of its squares. with_index takes this list and returns a list of tuples. The next map then subtracts the index from the value, generating a list that gets passed to IO.inspect.

So, this pipeline generates four lists on its way to outputting the final result.

Let’s look at something different. Here’s some code that reads lines from a file and returns the longest.

enum/longest_line.exs

IO.puts File.read!("/usr/share/dict/words")



|> String.split



|> Enum.max_by(&String.length/1)





In this case, we read the whole dictionary into memory (on my machine that’s 2.4MB), then split into a list of words (236,000 of them) before processing it to find the longest (which happens to be formaldehydesulphoxylate).

In both of these examples, our code is suboptimal because each call to Enum is self-contained. Each call takes a collection and returns a collection.

What we really want is to process the elements in the collection as we need them. We don’t need to store intermediate results as full collections; we just need to pass the current element from function to function. And that’s what streams do.





A Stream Is a Composable Enumerator


Here’s a simple example of creating a Stream:

iex> s = Stream.map [1, 3, 5, 7], &(&1 + 1)



#Stream<[enum: [1, 3, 5, 7], funs: [#Function<37.75994740/1 in Stream.map/2>] ]>





If we’d called Enum.map, we’d have seen the result [2,4,6,8] come back immediately. Instead we get back a stream value that contains a specification of what we intended.

How do we get the stream to start giving us results? Treat it as a collection and pass it to a function in the Enum module:

iex> s = Stream.map [1, 3, 5, 7], &(&1 + 1)



#Stream<...>



iex> Enum.to_list s



[2, 4, 6, 8]





Because streams are enumerable, you can also pass a stream to a stream function. Because of this, we say that streams are composable.

iex> squares = Stream.map [1, 2, 3, 4], &(&1*&1)



#Stream<[enum: [1, 2, 3, 4],



funs: [#Function<32.133702391 in Stream.map/2>] ]>





iex> plus_ones = Stream.map squares, &(&1+1)



#Stream<[enum: [1, 2, 3, 4],



funs: [#Function<32.133702391 in Stream.map/2>,



#Function<32.133702391 in Stream.map/2>] ]>





iex> odds = Stream.filter plus_ones, fn x -> rem(x,2) == 1 end



#Stream<[enum: [1, 2, 3, 4],



funs: [#Function<26.133702391 in Stream.filter/2>,



#Function<32.133702391 in Stream.map/2>,



#Function<32.133702391 in Stream.map/2>] ]>





iex> Enum.to_list odds



[5, 17]





Of course, in real life we’d have written this as

enum/stream1.exs

[1,2,3,4]



|> Stream.map(&(&1*&1))



|> Stream.map(&(&1+1))



|> Stream.filter(fn x -> rem(x,2) == 1 end)



|> Enum.to_list





Note that we’re never creating intermediate lists—we’re just passing successive elements of each of the collections to the next in the chain. The Stream values shown in the previous iex session give a hint of how this works—chained streams are represented as a list of functions, each of which is applied in turn to each element of the stream as it is processed.

Streams aren’t only for lists. More and more Elixir modules now support streams. For example, here’s our longest-word code written using streams:

enum/stream2.exs

IO.puts File.open!("/usr/share/dict/words")



|> IO.stream(:line)



|> Enum.max_by(&String.length/1)





The magic here is the call to IO.stream, which converts an IO device (in this case the open file) into a stream that serves one line at a time. In fact, this is such a useful concept that there’s a shortcut:

enum/stream3.exs

IO.puts File.stream!("/usr/share/dict/words") |> Enum.max_by(&String.length/1)





The good news is that there is no intermediate storage. The bad news is that it runs about two times slower than the previous version. However, consider the case where we were reading data from a remote server or from an external sensor (maybe temperature readings). Successive lines might arrive slowly, and they might go on for ever. With the Enum implementation we’d have to wait for all the lines to arrive before we started processing. With streams we can process them as they arrive.





Infinite Streams


Because streams are lazy, there’s no need for the whole collection to be available up front. For example, if I write

iex> Enum.map(1..10_000_000, &(&1+1)) |> Enum.take(5)



[2, 3, 4, 5, 6]





it takes about 8 seconds before I see the result. Elixir is creating a 10-million-element list, then taking the first five elements from it. If instead I write

iex> Stream.map(1..10_000_000, &(&1+1)) |> Enum.take(5)



[2, 3, 4, 5, 6]





the result comes back instantaneously. The take call just needs five values, which it gets from the stream. Once it has them, there’s no more processing.

In these examples the stream is bounded, but it can equally well go on forever, But to do that, we’ll need to create streams based on functions.





Creating Your Own Streams


Streams are implemented solely in Elixir libraries—there is no specific runtime support. However, this doesn’t mean you want to drop down to the very lowest level and create your own streamable types. The actual implementation is complex (in the same way that string theory and dating rituals are complex). Instead, you probably want to use some helpful wrapper functions to do the heavy lifting. There are a number of these, including cycle, repeatedly, iterate, unfold, and resource. (If you needed proof that the internal implementation is tricky, consider the fact that these last two names give you almost no hint of their power.)

Let’s start with the three simplest: cycle, repeatedly, and iterate.





Stream.cycle


Stream.cycle takes an enumerable and returns an infinite stream containing that enumerable’s elements. When it gets to the end, it repeats from the beginning, indefinitely. Here’s an example that generates the rows in an HTML table with alternating green and white classes:

iex> Stream.cycle(~w{ green white }) |>



...> Stream.zip(1..5) |>



...> Enum.map(fn {class, value} ->



...> ~s{<tr class="#{class}"><td>#{value}</td></tr>\n} end) |>



...> IO.puts



<tr class="green"><td>1</td></tr>



<tr class="white"><td>2</td></tr>



<tr class="green"><td>3</td></tr>



<tr class="white"><td>4</td></tr>



<tr class="green"><td>5</td></tr>





Stream.repeatedly


Stream.repeatedly takes a function and invokes it each time a new value is wanted.

iex> Stream.repeatedly(fn -> true end) |> Enum.take(3)



[true, true, true]



iex> Stream.repeatedly(&:random.uniform/0) |> Enum.take(3)



[0.7230402056221108, 0.94581636451987, 0.5014907142064751]





Stream.iterate


Stream.iterate(start_value, next_fun) generates an infinite stream. The first value is start_value. The next value is generated by applying next_fun to this value. This continues for as long as the stream is being used, with each value being the result of applying next_fun to the previous value.

Here are some examples:

iex> Stream.iterate(0, &(&1+1)) |> Enum.take(5)



[0, 1, 2, 3, 4]



iex> Stream.iterate(2, &(&1*&1)) |> Enum.take(5)



[2, 4, 16, 256, 65536]



iex> Stream.iterate([], &[&1]) |> Enum.take(5)



[[], [[]], [[[]]], [[[[]]]], [[[[[]]]]]]





Stream.unfold


Now we can get a little more adventurous. Stream.unfold is related to iterate, but you can be more explicit both about the values output to the stream and about the values passed to the next iteration. You supply an initial value and a function. The function uses the argument to create two values, returned as a tuple. The first is the value to be returned by this iteration of the stream, and the second is the value to be passed to the function on the next iteration of the stream. If the function returns nil, the stream terminates.

This sounds abstract, but unfold is quite useful—it is a general way of creating a potentially infinite stream of values where each value is some function of the previous state.

The key is the generating function. Its general form is

fn state -> { stream_value, new_state } end





For example, here’s a stream of Fibonacci numbers:

iex> Stream.unfold({0,1}, fn {f1,f2} -> {f1, {f2, f1+f2}} end) |> Enum.take(15)



[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377]





Here the state is a tuple containing the current and the next number in the sequence. We seed it with the initial state of {0, 1}. The value each iteration of the stream returns is the first of the state values. The new state moves one down the sequence, so an initial state of {f1,f2} becomes a new state of {f2,f1+f2}.





Stream.resource


At this point you might be wondering how streams can interact with external resources. We’ve already seen how you can turn a file’s contents into a stream of lines, but how could you implement this yourself? You’d need to open the file when the stream first starts, return successive lines, and then close the file at the end. Or maybe you want to turn a database result-set cursor into a stream of values. You’d have to execute the query when the stream starts, return each row as stream values, and close the query at the end. And that’s where Stream.resource comes in.

Stream.resource builds upon Stream.unfold. It makes two changes.

The first argument to unfold is the initial value to be passed to the iteration function. But if that value is a resource, we don’t want to open it until the stream starts delivering values, and that might not happen until long after we create the stream. To get around this, resource takes not a value, but a function that returns the value. That’s the first change.

Second, when the stream is done with the resource, we may need to close it. That’s what the third argument to Stream.resource does—it takes the final accumulator value and does whatever is needed to deallocate the resource.

Here’s an example from the library documentation:

Stream.resource(fn -> File.open("sample") end,



fn file ->



case IO.read(file, :line) do



line when is_binary(line) -> { [line], file }



_ -> {:halt, file}



end



end,



fn file -> File.close!(file) end)





The first function opens the file when the stream becomes active, and passes it to the second function. This reads the file, line by line, returning either a line and the file as a tuple, or a :halt tuple at the end of the file. The third function closes the file.

Let’s finish with a different kind of resource: time. We’ll implement a timer that counts down the number of seconds until the start of the next minute. It uses a stream resource to do this. The allocation function returns the number of seconds left until the next minute starts. It does this each time the stream is evaluated, so we’ll get a countdown that varies depending on when it is called.

The iteration function looks at the time left. If zero, it returns {:halt, 0}; otherwise it sleeps for a second and returns the current countdown as a string, along with the decremented counter.

In this case there’s no resource deallocation, so the third function does nothing.

Here’s the code:

enum/countdown.exs

defmodule Countdown do





def sleep(seconds) do



receive do



after seconds*1000 -> nil



end



end





def say(text) do



spawn fn -> :os.cmd('say #{text}') end



end





def timer do



Stream.resource(



fn -> # the number of seconds to the start of the next minute



{_h,_m,s} = :erlang.time



60 - s - 1



end,





fn # wait for the next second, then return its countdown



0 ->



{:halt, 0}





count ->



sleep(1)



{ [inspect(count)], count - 1 }



end,





fn _ -> end # nothing to deallocate



)



end



end





(The eagle-eyed among you will have noticed a function called say in the Countdown module. This executes the shell command say, which, on OS X, speaks its argument. You could substitute espeak on Linux and ptts on Windows.)

Let’s play with the code.

$ iex countdown.exs



iex> counter = Countdown.timer



#Function<17.133702391 in Stream.resource/3>



iex> printer = counter |> Stream.each(&IO.puts/1)



#Stream[enum: #Function<17.133702391 in Stream.resource/3>,



funs: [#Function<0.133702391 in Stream.each/2>] ]>



iex> speaker = printer |> Stream.each(&Countdown.say/1)



#Stream[enum: #Function<17.133702391 in Stream.resource/3>,



funs: [#Function<0.133702391 in Stream.each/2>,



#Function<0.133702391 in Stream.each/2>] ]>





So far, we’ve built a stream that creates time events, prints the countdown value, and speaks it. But there’s been no output, as we haven’t yet asked the stream for any values. Let’s do that now:

iex> speaker |> Enum.take(5)



37 ** numbers are output once



36 ** per second. Even cooler,the



35 ** computer says



34 ** "thirty seven", "thirty six"…



33



["37", "36", "35", "34", "33"]





Cool—we must have started it around 22 seconds into a minute, so the countdown starts at 37. Let’s use the same stream again, a few seconds later:

iex> speaker |> Enum.take(5)



29



28



27



26



25



["29", "28", "27", "26", "25"]





Wait some more seconds, and this time let it run to the top of the minute:

iex> speaker |> Enum.to_list



6



5



4



3



2



1



["6", "5", "4", "3","2", "1"]





This is clearly not great code, as it fails to correct the sleep time for any delays introduced by our code. But it illustrates a very cool point. Lazy streams let you deal with resources that are asynchronous to your code, and the fact that they are initialized every time they are used means they’re effectively side-effect-free. Every time we pipe our stream to an Enum function, we get a fresh set of values, computed at that time.





Streams in Practice


In the same way that functional programming requires you to look at problems in a new way, streams ask you to look at iteration and collections afresh. Not every situation where you are iterating requires a stream. But consider using a stream when you want to defer processing until you need the data, and when you need to deal with large numbers of things without necessarily generating them all at once.





The Collectable Protocol


The Enumerable protocol lets you iterate over the elements in a type—given a collection, you can get the elements. Collectable is in some sense the opposite—it allows you to build a collection by inserting elements into it.

Not all collections are collectable. Ranges, for example, cannot have new entries added to them.

The collectable API is pretty low-level, so you’ll typically access it via Enum.into and when using comprehensions (which we cover in the next section). For example, we can inject the elements of a range into an empty list using

iex> Enum.into 1..5, []



[1, 2, 3, 4, 5]





If the list is not empty, the new elements are tacked onto the end:

iex> Enum.into 1..5, [100, 101 ]



[100, 101, 1, 2, 3, 4, 5]





Output streams are collectable, so the following code lazily copies standard input to standard output:

iex> Enum.into IO.stream(:stdio, :line), IO.stream(:stdio, :line)





Comprehensions


When you’re writing functional code, you often map and filter collections of things. To make your life easier (and your code easier to read), Elixir provides a general-purpose shortcut for this: the comprehension.

The idea of a comprehension is fairly simple: given one or more collections, extract all combinations of values from each, optionally filter the values, and then generate a new collection using the values that remain.

The general syntax for comprehensions is deceptively simple:

result = for generator or filter… [, into: value ], do: expression

Let’s see a couple of basic examples before we get into the details.

iex> for x <- [ 1, 2, 3, 4, 5 ], do: x * x



[1, 4, 9, 16, 25]



iex> for x <- [ 1, 2, 3, 4, 5 ], x < 4, do: x * x



[1, 4, 9]





A generator specifies how you want to extract values from a collection.

pattern <- list





Any variables matched in the pattern are available in the rest of the comprehension (including the block). For example, x <- [1,2,3] says that we want to first run the rest of the comprehension with x set to 1. Then we run it with x set to 2, and so on. If we have two generators, their operations are nested, so

x <- [1,2], y <- [5,6]





will run the rest of the comprehension with x=1, y=5; x=1, y=6; x=2, y=5; and x=2, y=6. We can use those values of x and y in the do block.

iex> for x <- [1,2], y <- [5,6], do: x * y



[5, 6, 10, 12]



iex> for x <- [1,2], y <- [5,6], do: {x, y}



[{1, 5}, {1, 6}, {2, 5}, {2, 6}]





You can use variables from generators in later generators:

iex> min_maxes = [{1,4}, {2,3}, {10, 15}]



[{1, 4}, {2, 3}, {10, 15}]



iex> for {min,max} <- min_maxes, n <- min..max, do: n



[1, 2, 3, 4, 2, 3, 10, 11, 12, 13, 14, 15]





A filter is a predicate. It acts as a gatekeeper for the rest of the comprehension—if the condition is false, then the comprehension moves on to the next iteration without generating an output value.

For example, the code that follows uses a comprehension to list pairs of numbers from 1 to 8 whose product is a multiple of 10. It uses two generators (to cycle through the pairs of numbers) and two filters. The first filter allows only pairs in which the first number is at least the value of the second. The second filter checks to see if the product is a multiple of 10.

iex> first8 = [ 1,2,3,4,5,6,7,8 ]



[1, 2, 3, 4, 5, 6, 7, 8]



iex> for x <- first8, y <- first8, x >= y, rem(x*y, 10)==0, do: { x, y }



[{5, 2}, {5, 4}, {6, 5}, {8, 5}]





This comprehension iterates 64 times, with x=1, y=1; x=1, y=2; and so on. However, the first filter cuts the iteration short when x is less than y. This means the second filter runs only 36 times.

Because the first term in a generator is a pattern, we can use it to deconstruct structured data. Here’s a comprehension that swaps the keys and values in a keyword list.

iex> reports = [ dallas: :hot, minneapolis: :cold, dc: :muggy, la: :smoggy ]



[dallas: :hot, minneapolis: :cold, dc: :muggy, la: :smoggy]



iex> for { city, weather } <- reports, do: { weather, city }



[hot: :dallas, cold: :minneapolis, muggy: :dc, smoggy: :la]





Comprehensions Work on Bits, Too


A bitstring (and, by extension, a binary or a string) is simply a collection of ones and zeroes. So it’s probably no surprise that comprehensions work bits, too. What might be surprising is the syntax:

iex> for << ch <- "hello" >>, do: ch



'hello'



iex> for << ch <- "hello" >>, do: <<ch>>



["h", "e", "l", "l", "o"]





Here the generator is enclosed in << and >>, indicating a binary. In the first case, the do block returns the integer code for each character, so the resulting list is [104, 101, 108, 108, 111], which iex displays as 'hello'.

In the second case, we convert the code back into a string, and the result is a list of those one-character strings.

Again, the thing to the left of the <- is a pattern, and so we can use binary pattern matching. Let’s convert a string into the octal representation of its characters:

iex> for << << b1::size(2), b2::size(3), b3::size(3) >> <- "hello" >>,



...> do: "0#{b1}#{b2}#{b3}"



["0150", "0145", "0154", "0154", "0157"]





Scoping and Comprehensions


All variable assignments inside a comprehension are local to that comprehension—you will not affect the value of a variable in the outer scope.

iex> name = "Dave"



"Dave"



iex> for name <- [ "cat", "dog" ], do: String.upcase(name)



["CAT", "DOG"]



iex> name



"Dave"



iex>





The Value Returned by a Comprehension


In our examples so far, the comprehension has returned a list. The list contains the values returned by the do expression for each iteration of the comprehension.

This behavior can be changed with the into: parameter. This takes a collection that is to receive the results of the comprehension. For example, we can populate a map using

iex> for x <- ~w{ cat dog }, into: %{}, do: { x, String.upcase(x) }



%{"cat" => "CAT", "dog" => "DOG"}





It might be more clear to use Map.new in this case:

iex> for x <- ~w{ cat dog }, into: Map.new, do: { x, String.upcase(x) }



%{"cat" => "CAT", "dog" => "DOG"}





The collection doesn’t have to be empty:

iex> for x <- ~w{ cat dog }, into: %{"ant" => "ANT"}, do: { x, String.upcase(x) }



%{"ant" => "ANT", "cat" => "CAT", "dog" => "DOG"}





In Chapter 22, Protocols—Polymorphic Functions, we’ll look at protocols, which let us specify common behaviors across different types. The into: option takes values that implement the Collectable protocol. These include lists, binaries, functions, maps, files, hash dicts, hash sets, and IO streams, so we can write things such as

iex> for x <- ~w{ cat dog }, into: IO.stream(:stdio,:line), do: "<<#{x}>>\n"



<<cat>>



<<dog>>



%IO.Stream{device: :standard_io, line_or_bytes: :line, raw: false}





Your Turn


Exercise: ListsAndRecursion-7

In the last exercise of Chapter 7, Lists and Recursion, you wrote a span funtion. Use it and list comprehensions to return a list of the prime numbers from 2 to n.



Exercise: ListsAndRecursion-8

The Pragmatic Bookshelf has offices in Texas (TX) and North Carolina (NC), so we have to charge sales tax on orders shipped to these states. The rates can be expressed as a keyword list:[17] tax_rates = [ NC: 0.075, TX: 0.08 ]





Here’s a list of orders: orders = [



[ id: 123, ship_to: :NC, net_amount: 100.00 ],



[ id: 124, ship_to: :OK, net_amount: 35.50 ],



[ id: 125, ship_to: :TX, net_amount: 24.00 ],



[ id: 126, ship_to: :TX, net_amount: 44.80 ],



[ id: 127, ship_to: :NC, net_amount: 25.00 ],



[ id: 128, ship_to: :MA, net_amount: 10.00 ],



[ id: 129, ship_to: :CA, net_amount: 102.00 ],



[ id: 120, ship_to: :NC, net_amount: 50.00 ] ]





Write a function that takes both lists and returns a copy of the orders, but with an extra field, total_amount, which is the net plus sales tax. If a shipment is not to NC or TX, there’s no tax applied.





Moving Past Divinity


L. Peter Deutsch once penned, “To iterate is human, to recurse divine.” And that’s certainly the way I felt when I first started coding Elixir. The joy of pattern-matching lists in sets of recursive functions drove my designs. After a while, I realized that perhaps I was taking this too far.

In reality, most of our day-to-day work is better handled using the various enumerators built into Elixir. They make your code smaller, easier to understand, and probably more efficient.

Part of the process of learning to be effective in Elixir is working out for yourself when to use recursion and when to use enumerators. I recommend enumerating when you can.

Next we’ll look at string handling in Elixir (and Erlang).





Footnotes


[16]

http://elixir-lang.org/docs/



[17]

I wish it were that simple.…



