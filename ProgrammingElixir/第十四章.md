



Chapter 14





Working with Multiple Processes




* * *





‣

One of Elixir’s key features is the idea of packaging code into small chunks that can be run independently and concurrently.

If you’ve come from a conventional programming language, this may worry you. Concurrent programming is “known” to be difficult, and there’s a performance penalty to pay when you create lots of processes.

Elixir doesn’t have these issues, thanks to the architecture of the Erlang VM on which it runs.

Elixir uses the actor model of concurrency. An actor is an independent process that shares nothing with any other process. You can spawn new processes, send them messages, and receive messages back. And that’s it (apart from some details about error handling and monitoring, which we cover later).

In the past, you may have had to use threads or operating-system processes to achieve concurrency. Each time, you probably felt you were opening Pandora’s box—there was so much that could go wrong. But that worry just evaporates in Elixir. In fact, Elixir developers are so comfortable creating new processes, they’ll often do it at times when you’d have created an object in a language such as Java.

One more thing—when we talk about processes in Elixir, we are not talking about native operating-system processes. These are too slow and bulky. Instead, Elixir uses process support in Erlang. These processes will run across all your CPUs (just like native processes), but they have very little overhead. As we’ll cover a bit later, it’s very easy to create hundreds of thousands of Elixir processes on even a modest computer.





A Simple Process


Here’s a module that defines a function we’d like to run as a separate process.

spawn/spawn-basic.ex

defmodule SpawnBasic do



def greet do



IO.puts "Hello"



end



end





Yup, that’s it. There’s nothing special—it’s just regular code.

Let’s fire up iex and play:

iex> c("spawn-basic.ex")



[SpawnBasic]





First let’s call it as a regular function:

iex> SpawnBasic.greet



Hello



:ok





Now let’s run it in a separate process:

iex> spawn(SpawnBasic, :greet, [])



Hello



#PID<0.42.0>





The spawn function kicks off a new process. It comes in many forms, but the two simplest ones let you run an anonymous function and run a named function in a module, passing a list of arguments. (We used the latter here.)

The spawn returns a Process Identifier, normally called a PID. This uniquely identifies the process it creates. (This identifier could be unique among all processes in the world, but here it’s just unique in our application.)

When we call spawn, it creates a new process to run the code we specify. We don’t know exactly when it will execute—we know only that it is eligible to run.

In this example, we can see that our function ran and output “Hello” prior to iex reporting the PID returned by spawn. But you can’t rely on this. Instead you’ll use messages to synchronize your processes’ activity.





Sending Messages Between Processes


Let’s rewrite our example to use messages. The top level will send greet a message containing a string, and the greet function will respond with a greeting containing that message.

In Elixir we send a message using the send function. It takes a PID and the message to send (an Elixir value, which we also call a term) on the right. You can send anything you want, but most Elixir developers seem to use atoms and tuples.

We wait for messages using receive. In a way, this acts just like case, with the message body as the parameter. Inside the block associated with the receive call, you can specify any number of patterns and associated actions. Just as with case, the action associated with the first pattern that matches the function is run.

Here’s the updated version of our greet function.

spawn/spawn1.ex

defmodule Spawn1 do



def greet do



receive do



{sender, msg} ->



send sender, { :ok, "Hello, #{msg}" }



end



end



end





# here's a client



pid = spawn(Spawn1, :greet, [])



send pid, {self, "World!"}





receive do



{:ok, message} ->



IO.puts message



end





The function uses receive to wait for a message, and then matches the message in the block. In this case, the only pattern is a two-element tuple, where the first element is the original sender’s PID and the second is the message. In the corresponding action, we use send sender, ... to send a formatted string back to the original message sender. We package that string into a tuple, with :ok as its first element.

Outside the module, we call spawn to create a process, and send it a tuple:

send pid, { self, "World!" }





The function self returns its caller’s PID. Here we use it to pass our PID to the greet function so it will know where to send the response.

We then wait for a response. Notice that we do a pattern match on {:ok, message}, extracting the second element of the tuple, which contains the actual text.

We can run this in iex:

iex> c("spawn1.ex")



Hello, World!



[Spawn1]





Very cool. The text was sent, and greet responded with the full greeting.





Handling Multiple Messages


Let’s try sending a second message.

spawn/spawn2.ex

defmodule Spawn2 do



def greet do



receive do



{sender, msg} ->



send sender, { :ok, "Hello, #{msg}" }



end



end



end





# here's a client



pid = spawn(Spawn2, :greet, [])





send pid, {self, "World!"}





receive do



{:ok, message} ->



IO.puts message



end





send pid, {self, "Kermit!"}



receive do



{:ok, message} ->



IO.puts message



end





Run it in iex:

iex> c("spawn2.ex")



Hello World!



.... just sits there ....





The first message is sent back, but the second is nowhere to be seen. What’s worse, iex just hangs, and we have to use ^C (the control-C key sequence) to get out of it.

That’s because our greet function handles only a single message. Once it has processed the receive, it exits. As a result, the second message we send it is never processed. The second receive at the top level then just hangs, waiting for a response that will never come.

Let’s at least fix the hanging part. We can tell receive that we want to time out if a response is not received in so many milliseconds. This uses a pseudopattern called after.

spawn/spawn3.ex

defmodule Spawn3 do



def greet do



receive do



{sender, msg} ->



send sender, { :ok, "Hello, #{msg}" }



end



end



end





# here's a client



pid = spawn(Spawn3, :greet, [])





send pid, {self, "World!"}



receive do



{:ok, message} ->



IO.puts message



end





send pid, {self, "Kermit!"}



receive do



{:ok, message} ->



IO.puts message



» after 500 ->



» IO.puts "The greeter has gone away"



end





iex> c("spawn3.ex")



Hello World!



... short pause ...



The greeter has gone away



[Spawn3]





But how would we make our greet function handle multiple messages? Our natural reaction is to make it loop, doing a receive on each iteration. Elixir doesn’t have loops, but it does have recursion.

spawn/spawn4.ex

defmodule Spawn4 do



def greet do



receive do



{sender, msg} ->



send sender, { :ok, "Hello, #{msg}" }



» greet



end



end



end





# here's a client



pid = spawn(Spawn4, :greet, [])



send pid, {self, "World!"}



receive do



{:ok, message} ->



IO.puts message



end





send pid, {self, "Kermit!"}



receive do



{:ok, message} ->



IO.puts message



after 500 ->



IO.puts "The greeter has gone away"



end





Run this, and both messages are processed:

iex> c("spawn4.ex")



Hello World!



Hello Kermit!



[Spawn4]





Recursion, Looping, and the Stack


The recursive greet function might have worried you a little. Every time it receives a message, it ends up calling itself. In many languages, that adds a new frame to the stack. After a large number of messages, you might run out of memory.

This doesn’t happen in Elixir, as it implements tail-call optimization. If the very last thing a function does is call itself, there’s no need to make the call. Instead, the runtime can simply jump back to the start of the function. If the recursive call has arguments, then these replace the original parameters as the loop occurs.

But beware—the recursive call must be the very last thing executed. For example, the following code is not tail recursive:

def factorial(0), do: 1



def factorial(n), do: n * factorial(n-1)





Although the recursive call is physically the last thing in the function, it is not the last thing executed. The function has to multiply the value it returns by n.

To make it tail recursive, we need to move the multiplication into the recursive call, and this means adding an accumulator:

spawn/fact_tr.ex

defmodule TailRecursive do



def factorial(n), do: _fact(n, 1)



defp _fact(0, acc), do: acc



defp _fact(n, acc), do: _fact(n-1, acc*n)



end





Process Overhead


At the start of the chapter, I somewhat cavalierly said Elixir processes were very low overhead. Now it is time to back that up. Let’s write some code that creates n processes. The first will send a number to the second. It will increment that number and pass it to the third. This will continue until we get to the last process, which will pass the number back to the top level.

spawn/chain.exs

Line 1defmodule Chain do



- def counter(next_pid) do



- receive do



- n ->



5 send next_pid, n + 1



- end



- end



-



- def create_processes(n) do



10 last = Enum.reduce 1..n, self,



- fn (_,send_to) ->



- spawn(Chain, :counter, [send_to])



- end



-



15 # start the count by sending



- send last, 0



-



- # and wait for the result to come back to us



- receive do



20 final_answer when is_integer(final_answer) ->



- "Result is #{inspect(final_answer)}"



- end



- end



-



25 def run(n) do



- IO.puts inspect :timer.tc(Chain, :create_processes, [n])



- end



- end





The counter function on line 2 is the code that will be run in separate processes. It is passed the PID of the next process in the chain. When it receives a number, it increments it and sends it on to that next process.

The create_processes function is probably the densest piece of Elixir we’ve encountered so far. Let’s break it down.

It is passed the number of processes to create. Each process has to be passed the PID of the previous process so that it knows who to send the updated number to. All this is done on line 11.

The reduce call will iterate over the range 1..n. Each time around, it will pass an accumulator as the second parameter to its function. We set the initial value of that accumulator to self, our PID.

In the function, we spawn a new process that runs the counter function, using the third parameter of spawn to pass in the accumulator’s current value (initially self). The value spawn returns is the PID of the newly created process, which becomes the accumulator’s value for the next iteration.

Putting it another way, each time we spawn a new process, we pass it the previous process’s PID in the send_to parameter.

The value that the reduce function returns is the accumulator’s final value, which is the PID of the last process created.

On the next line we set the ball rolling by passing 0 to the last process. It will increment it and pass 1 to the second-to-last process. This goes on until the very first process we created passes the result back to us. We use the receive block to capture this, and format it into a nice message.

Our receive block contains a new feature. We’ve already seen how guard clauses can constrain pattern matching and function calling. The same guard clauses can be used to qualify the pattern in a receive block.

Why do we need this, though? It turns out there’s a bug in some versions of Elixir.[25] When you compile and run a program using iex -S mix, a residual message is left lying around from the compilation process (it records a process’s termination). We ignore that message by telling the receive clause that we’re interested only in simple integers.

The run function starts the whole thing off. It uses a built-in Erlang library, tc, which can time a function’s execution. We pass it the module, name, and parameters, and it responds with a tuple. The first element is the execution time in microseconds and the second is the result the function returns.

We’ll run this code from the command line rather than from iex. (You’ll see why in a second.) These results are on my 2011 MacBook Air (2.13GHz Core 2 Duo and 4GB RAM).

$ elixir -r chain.exs -e "Chain.run(10)"



{3175,"Result is 10"}





We asked it to run 10 processes, and it came back in 3.175 ms. The answer looks correct. Let’s try 100 processes.

$ elixir -r chain.exs -e "Chain.run(100)"



{3584,"Result is 100"}





Only a small increase in the time. There’s probably some startup latency on the first process creation. Onward! Let’s try 1,000.

$ elixir -r chain.exs -e "Chain.run(1000)"



{8838,"Result is 1000"}





Now 10,000.

$ elixir -r chain.exs -e "Chain.run(10000)"



{76550,"Result is 10000"}





Ten thousand processes created and executed in 77 ms. Let’s try for 400,000.

$ elixir -r chain.exs -e "Chain.run(400_000)"



=ERROR REPORT==== 25-Apr-2013::15:16:14 ===



Too many processes



** (SystemLimitError) a system limit has been reached





It looks like the virtual machine won’t support 400,000 processes. Fortunately, this is not a hard limit—we just bumped into a default value. We can increase this using the VM’s +P parameter. We pass this parameter to the VM using the --erl parameter to elixir. (This is why I chose to run from the command line.)

$ elixir --erl "+P 1000000" -r chain.exs -e "Chain.run(400_000)"



{3210704,"Result is 400000"}





One last run, this time with 1,000,000 processes.

$ elixir --erl "+P 1000000" -r chain.exs -e "Chain.run(1_000_000)"



{7225292,"Result is 1000000"}





We ran a million processes (sequentially) in about 7 seconds. This kind of performance is stunning, and it changes the way we design code. We can now create hundreds of little helper processes. And each process can contain its own state—in a way, processes in Elixir are like objects in an object-oriented system (but they have a better sense of humor).





Your Turn


Exercise: WorkingWithMultipleProcesses-1

Run this code on your machine. See if you get comparable results.



Exercise: WorkingWithMultipleProcesses-2

Write a program that spawns two processes and then passes each a unique token (for example, “fred” and “betty”). Have them send the tokens back.Is the order in which the replies are received deterministic in theory? In practice?

If either answer is no, how could you make it so?





When Processes Die


Who gets told when a process dies? By default, no one. Obviously the VM knows and can report it to the console, but your code will be oblivious unless you explicitly tell Elixir you want to get involved.

Here’s the default case: we spawn a function that uses the Erlang timer library to sleep for 500 ms. It then exits with a status of 99.

The code that spawns it sits in a receive. If it receives a message, it reports that fact; otherwise, after one second it lets us know that nothing happened.

spawn/link1.exs

defmodule Link1 do



import :timer, only: [ sleep: 1 ]





def sad_function do



sleep 500



exit(:boom)



end



def run do



Process.flag(:trap_exit, true)



spawn(Link1, :sad_function, [])



receive do



msg ->



IO.puts "MESSAGE RECEIVED: #{inspect msg}"



after 1000 ->



IO.puts "Nothing happened as far as I am concerned"



end



end



end





Link1.run





(Think about how you’d have written this in your old programming language.)

We can run this from the console:

$ elixir -r link1.exs



Nothing happened as far as I am concerned





As far as the top level was concerned, the spawned process exiting caused no activity.





Linking Two Processes




If we want two processes to share in each other’s pain, we can link them. When processes are linked, each can receive information when the other exits. The spawn_link call spawns a process and links it to the caller in one operation.

spawn/link2.exs

defmodule Link2 do



import :timer, only: [ sleep: 1 ]





def sad_function do



sleep 500



exit(:boom)



end



def run do



» spawn_link(Link2, :sad_function, [])



receive do



msg ->



IO.puts "MESSAGE RECEIVED: #{inspect msg}"



after 1000 ->



IO.puts "Nothing happened as far as I am concerned"



end



end



end





Link2.run





The runtime reports the abnormal termination:

$ elixir -r link2.exs



** (EXIT from #PID<0.35.0>) :boom





So our child process died, and it killed the entire application. That’s the default behaviour of linked processes—when one exits abnormally, it kills the other.

What if you want to handle the death of another process? Well, you probably don’t want to do this. Elixir uses the OTP framework for constructing process trees, and OTP includes the concept of process supervision. An incredible amount of effort has been spent getting this right, so I recommend using it most of the time. (We cover this in Chapter 17, OTP: Supervisors.)

However, you can tell Elixir to convert the exit signals from a linked process into a message you can handle. Do this by trapping the exit.

spawn/link3.exs

defmodule Link3 do



import :timer, only: [ sleep: 1 ]





def sad_function do



sleep 500



exit(:boom)



end



def run do



» Process.flag(:trap_exit, true)



spawn_link(Link3, :sad_function, [])



receive do



msg ->



IO.puts "MESSAGE RECEIVED: #{inspect msg}"



after 1000 ->



IO.puts "Nothing happened as far as I am concerned"



end



end



end





Link3.run





This time we see an :EXIT message when the spawned process terminates:

$ elixir -r link3.exs



MESSAGE RECEIVED: {:EXIT, #PID<0.41.0>, :boom}





It doesn’t matter why a process exits—it may simply finish processing, it may explicitly exit, or it may raise an exception—the same :EXIT message is received. Following an error, however, it contains details of what went wrong.





Monitoring a Process


Linking joins the calling process and another process—each receives notifications about the other. By contrast, monitoring lets a process spawn another and be notified of its termination, but without the reverse notification—it is one-way only.

When you monitor a process, you receive a :DOWN message when it exits or fails, or if it doesn’t exist.

You can use spawn_monitor to turn on monitoring when you spawn a process, or you can use Process.monitor to monitor an existing process. However, if you use Process.monitor (or link to an existing process), there is a potential race condition—if the other process dies before your monitor call completes, you may not receive a notification. The spawn_link and spawn_monitor versions are atomic, however, so you’ll always catch a failure.

spawn/monitor1.exs

defmodule Monitor1 do



import :timer, only: [ sleep: 1 ]





def sad_method do



sleep 500



exit(:boom)



end





def run do



» res = spawn_monitor(Monitor1, :sad_method, [])



IO.puts inspect res



receive do



msg ->



IO.puts "MESSAGE RECEIVED: #{inspect msg}"



after 1000 ->



IO.puts "Nothing happened as far as I am concerned"



end



end



end





Monitor1.run





Run it, and the results are similar to the spawn_link version:

$ elixir -r monitor1.exs -e Monitor1.run



{#PID<0.37.0>,#Reference<0.0.0.53>}



MESSAGE RECEIVED: {:DOWN,#Reference<0.0.0.53>,:process,#PID<0.37.0>,:boom}





(The Reference record in the message is the identity of the monitor that was created. The spawn_monitor call also returns it, along with the PID.)

So, when do you use links and when should you choose monitors?

It depends on your processes’ semantics. If the intent is that a failure in one process should terminate another, then you need links. If instead you need to know when some other process exits for any reason, choose monitors.





Your Turn


The Erlang function timer.sleep(time_in_ms) suspends the current process for a given time. You might want to use it to force some scenarios in the following exercises. The key with the exercises is to get used to the different reports you’ll see when you’re developing code.

Exercise: WorkingWithMultipleProcesses-3

Use spawn_link to start a process, and have that process send a message to the parent and then exit immediately. Meanwhile, sleep for 500 ms in the parent, then receive as many messages as are waiting. Trace what you receive. Does it matter that you weren’t waiting for the notification from the child when it exited?



Exercise: WorkingWithMultipleProcesses-4

Do the same, but have the child raise an exception. What difference do you see in the tracing?



Exercise: WorkingWithMultipleProcesses-5

Repeat the two, changing spawn_link to spawn_monitor.





Parallel Map—The “Hello, World” of Erlang


Devin Torres reminded me that every book in the Erlang space must, by law, include a definition of a parallel map function. Regular map returns the list that results from applying a function to each element of a collection. The parallel version does the same, but it applies the function to each element in a separate process.

spawn/pmap.exs

defmodule Parallel do



def pmap(collection, fun) do



me = self



collection



|> Enum.map(fn (elem) ->



spawn_link fn -> (send me, { self, fun.(elem) }) end



end)



|> Enum.map(fn (pid) ->



receive do { ^pid, result } -> result end



end)



end



end





Our method contains two transformations (look for the |> operator). The first transformation maps collection into a list of PIDs, where each PID in the list runs the given function on an individual list element. If the collection contains 1,000 items, we’ll run 1,000 processes.

The second transformation converts the list of PIDs into the results returned by the processes corresponding to each PID in the list. Note how it uses ^pid in the receive block to get the result for each PID in turn. Without this we’d get back the results in random order.

But does it work?

iex> c("pmap.exs")



[Parallel]



iex> Parallel.pmap 1..10, &(&1 * &1)



[1,4,9,16,25,36,49,64,81,100]





That’s pretty sweet.

But it gets better, as we’ll cover when we look at tasks and agents.





Your Turn


Exercise: WorkingWithMultipleProcesses-6

In the pmap code, I assigned the value of self to the variable me at the top of the method and then used me as the target of the message returned by the spawned processes. Why use a separate variable here?



Exercise: WorkingWithMultipleProcesses-7

Change the ^pid in pmap to _pid. This means the receive block will take responses in the order the processes send them. Now run the code again. Do you see any difference in the output? If you’re like me, you don’t, but the program clearly contains a bug. Are you scared by this? Can you find a way to reveal the problem (perhaps by passing in a different function, by sleeping, or by increasing the number of processes)? Change it back to ^pid and make sure the order is now correct.





A Fibonacci Server


Let’s round out this chapter with an example program. Its task is to calculate fib(n) for a list of n, where fib(n) is the nth Fibonacci number. (The Fibonacci sequence starts 0, 1. Each subsequent number is the sum of the preceding two numbers in the sequence.)[26] I chose this not because it is something we all do every day, but because the naïve calculation of Fibonacci numbers 10 through 37 takes a measurable number of seconds on typical computers.

The twist is that we’ll write our program to calculate different Fibonacci numbers in parallel. To do this, we’ll write a trivial server process that does the calculation, and a scheduler that assigns work to a calculation process when it becomes free. The following diagram shows the message flow.



When the calculator is ready for the next number, it sends a :ready message to the scheduler. If there is still work to do, the scheduler sends it to the calculator in a :fib message; otherwise it sends the calculator a :shutdown. When a calculator receives a :fib message, it calculates the given Fibonacci number and returns it in an :answer. If it gets a :shutdown, it simply exits.

Here’s the Fibonacci calculator module:

spawn/fib.exs

defmodule FibSolver do





def fib(scheduler) do



send scheduler, { :ready, self }



receive do



{ :fib, n, client } ->



send client, { :answer, n, fib_calc(n), self }



fib(scheduler)



{ :shutdown } ->



exit(:normal)



end



end





# very inefficient, deliberately



defp fib_calc(0), do: 0



defp fib_calc(1), do: 1



defp fib_calc(n), do: fib_calc(n-1) + fib_calc(n-2)



end





The public API is the fib function, which takes the scheduler PID. When it starts, it sends a :ready message to the scheduler and then waits for a message back.

If it gets a :fib message, it calculates the answer and sends it back to the client. It then loops by calling itself recursively. This will send another :ready message, telling the client it is ready for more work.

If it gets a :shutdown it simply exits.





The Task Scheduler


The scheduler is a little more complex, as it is designed to handle both a varying number of server processes and an unknown amount of work.

spawn/fib.exs

defmodule Scheduler do





def run(num_processes, module, func, to_calculate) do



(1..num_processes)



|> Enum.map(fn(_) -> spawn(module, func, [self]) end)



|> schedule_processes(to_calculate, [])



end





defp schedule_processes(processes, queue, results) do



receive do



{:ready, pid} when length(queue) > 0 ->



[ next | tail ] = queue



send pid, {:fib, next, self}



schedule_processes(processes, tail, results)





{:ready, pid} ->



send pid, {:shutdown}



if length(processes) > 1 do



schedule_processes(List.delete(processes, pid), queue, results)



else



Enum.sort(results, fn {n1,_}, {n2,_} -> n1 <= n2 end)



end





{:answer, number, result, _pid} ->



schedule_processes(processes, queue, [ {number, result} | results ])



end



end



end





The public API for the scheduler is the run function. It receives the number of processes to spawn, the module and function to spawn, and a list of things to process. The scheduler is pleasantly ignorant of the actual task being performed.

Let’s emphasize that last point. Our scheduler knows nothing about Fibonacci numbers. Exactly the same code will happily manage processes working on DNA sequencing or cracking passwords.

The run function spawns the correct number of processes and records their PIDs. It then calls the workhorse function, schedule_processes.

This function is basically a receive loop. If it gets a :ready message from a server, it sees if there is more work in the queue. If there is, it passes the next number to the calculator and then recurses with one fewer number in the queue.

If the work queue is empty when it receives a :ready message, it sends a shutdown to the server. If this is the last process, then we’re done and it sorts the accumulated results. If it isn’t the last process, it removes the process from the list of processes and recurses to handle another message.

Finally, if it gets an :answer message, it records the answer in the result accumulator and recurses to handle the next message.

We drive the scheduler with the following code:

spawn/fib.exs

to_process = [ 37, 37, 37, 37, 37, 37 ]





Enum.each 1..10, fn num_processes ->



{time, result} = :timer.tc(Scheduler, :run,



[num_processes, FibSolver, :fib, to_process])



if num_processes == 1 do



IO.puts inspect result



IO.puts "\n # time (s)"



end



:io.format "~2B ~.2f~n", [num_processes, time/1000000.0]



end





The to_process list contains the numbers we’ll be passing to our fib servers. In our case, we give it the same number, 37, ten times. The intent here is to load each of our processors.

We run the code a total of 10 times, varying the number of spawned processes from 1 to 10. We use :timer.tc to determine the elapsed time of each iteration, reporting the result in seconds. The first time around the loop, we also display the numbers we calculated.

$ elixir fib.exs



[{37, 39088169}, {37, 39088169}, {37, 39088169}, {37, 39088169},



{37, 39088169}, {37, 39088169}]





# time (s)



1 6.57



2 3.91



3 3.53



4 3.38



5 3.41



6 3.36



7 3.38



8 3.40



9 3.39



10 3.44





On my four-core system, we see a dramatic reduction in elapsed time when we increase the concurrency from one to two, small decreases until we hit four processes, then fairly flat performance after that. If you want to see similar results on systems with more cores, you’ll need to increase the number of entries in the to_process list.





Your Turn


Exercise: WorkingWithMultipleProcesses-8

Run the Fibonacci code on your machine. Do you get comparable timings? If your machine has multiple cores and/or processors, do you see improvements in the timing as we increase the application’s concurrency?



Exercise: WorkingWithMultipleProcesses-9

Take this scheduler code and update it to let you run a function that finds the number of times the word “cat” appears in each file in a given directory. Run one server process per file. The function File.ls! returns the names of files in a directory, and File.read! reads the contents of a file as a binary. Can you write it as a more generalized scheduler?

Run your code on a directory with a reasonable number of files (maybe around 100) so you can experiment with the effects of concurrency.





Agents—A Teaser


Our Fibonacci code is seriously inefficient. To calculate fib(5), we calculate this:

fib(5)



= fib(4) + fib(3)



= fib(3) + fib(2) + fib(2) + fib(1)



= fib(2) + fib(1) + fib(1) + fib(0) + fib(1) + fib(0) + fib(1)



= fib(1) + fib(0) + fib(1) + fib(1) + fib(0) + fib(1) + fib(0) + fib(1)





Look at all that duplication. If only we could cache the intermediate values.

As you know, Elixir modules are basically buckets of functions—they cannot hold state. But processes can hold state. And Elixir comes with a library module called Agent that makes it easy to wrap a process containing state in a nice module interface. Don’t worry about the details of the code that follows—we cover agents and tasks. For now, just see how processes are among the tools we use to add persistence to Elixir code. (This code comes from a mailing-list post by José Valim, written in response to some really ugly code I wrote.)

spawn/fib_agent.exs

defmodule FibAgent do



def start_link do



cache = Enum.into([{0, 0}, {1, 1}], HashDict.new)



Agent.start_link(fn -> cache end)



end





def fib(pid, n) when n >= 0 do



Agent.get_and_update(pid, &do_fib(&1, n))



end





defp do_fib(cache, n) do



if cached = cache[n] do



{cached, cache}



else



{val, cache} = do_fib(cache, n - 1)



result = val + cache[n-2]



{result, Dict.put(cache, n, result)}



end



end



end





{:ok, agent} = FibAgent.start_link()



IO.puts FibAgent.fib(agent, 2000)





Let’s run it:

$ elixir fib_agent.exs



42246963333923048787067256023414827825798528402506810980102801373143085843701



30707224123599639141511088446087538909603607640194711643596029271983312598737



32625355580260699158591522949245390499872225679531698287448247299226390183371



67780606070116154978867198798583114688708762645973690867228840236544222952433



47964480139515349562972087652656069529806499841977448720155612802665404554171



717881930324025204312082516817125





If we’d tried to calulate fib(2000) using the noncached version, the sun would grow to engulf the Earth while we were waiting for it to finish.





Thinking in Processes


If you first started programming with procedural languages and then moved to an object-oriented style, you’ll have experienced a period of dislocation as you tried to get your head to think in terms of objects.

The same will be happening now as you start to think of your work in terms of processes. Just about every decent Elixir program will have many, many processes, and by and large they’ll be just as easy to create and manage as the objects were in object-oriented programming. But learning to think that way takes awhile. Stick with it.

So far we’ve been running our processes in the same VM. But if we’re planning on taking over the world, we need to be able to scale. And that means running on more than one machine.

The abstraction for this is the node, and that’s the subject of the next chapter.





Footnotes


[25]

https://github.com/elixir-lang/elixir/issues/1050



[26]

http://en.wikipedia.org/wiki/Fibonacci_number


